<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Qualcomm¬Æ AI Engine Direct</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom_css.css?v=e00ba12e" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=474e5199"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Qualcomm¬Æ AI Engine Direct
          </a>
              <div class="version">
                2.24
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Qualcomm¬Æ AI Engine Direct</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p># Setup for Linux Host (Ubuntu, WSL, and other distros)</p>
<p>Follow these instructions to install the Qualcomm AI Engine Direct SDK <strong>(commonly referred to as the QNN SDK)</strong> and all necessary dependencies.</p>
<p>&lt;aside&gt;
‚≠ê This guide is for a host machine running Linux. If you are using a Windows machine, please follow the instructions for a Windows setup.</p>
<p>&lt;/aside&gt;</p>
<p>The QNN SDK allows you to convert an AI model (e.g., a <cite>.pt</cite> model from PyTorch) into instructions that can be run on a target device‚Äôs various processing units (CPU, GPU, HTP, cDSP, or LPAI).</p>
<p>&lt;aside&gt;
‚≠ê To learn about acronyms which are new to you, see the Glossary.</p>
<p>&lt;/aside&gt;</p>
<p>You will need to install the following code to use the QNN SDK:</p>
<ol class="arabic simple">
<li><p>The QNN SDK binary and its immediate dependencies.</p></li>
<li><p>ML frameworks to interpret your AI model files. (e.g., <cite>PyTorch</cite>)</p></li>
<li><dl class="simple">
<dt>Toolchain code for your target device‚Äôs operating system.</dt><dd><ol class="arabic simple">
<li><p>e.g., To develop on Android, you will need to install an Android NDK.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Packages/tooling to build the converted models for specific hardware processors (CPU, GPU, HTP, cDSP, or LPAI).</p></li>
</ol>
<p>&lt;aside&gt;
‚≠ê This guide contains many recommendations about specific versions of code to use that have been verified to work. Other versions of those dependencies may or may not work, so use them at your own risk.</p>
<p>&lt;/aside&gt;</p>
<p>## 1. Install Qualcomm AI Engine Direct (aka the ‚ÄúQNN SDK‚Äù)</p>
<ol class="arabic simple">
<li><p>Go to the QNN SDK product page: <a class="reference external" href="https://www.qualcomm.com/developer/software/qualcomm-ai-engine-direct-sdk">https://www.qualcomm.com/developer/software/qualcomm-ai-engine-direct-sdk</a></p></li>
<li><dl class="simple">
<dt>Click ‚ÄúGet Software‚Äù to download the QNN SDK</dt><dd><ol class="arabic simple">
<li><p>Note: The QNN SDK is ~2 GB when unzipped.</p></li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Unzip the downloaded SDK.</dt><dd><ol class="arabic simple">
<li><p>The zipped file should have a name like <cite>v2.22.6.240515</cite>.</p></li>
<li><p>When unzipped, the folder should be named <cite>qairt</cite> with a sub-folder that looks like <cite>2.22.6.240515</cite>.</p></li>
</ol>
</dd>
</dl>
</li>
</ol>
<p>### Set up your environment</p>
<ol class="arabic">
<li><p>Open a terminal.</p></li>
<li><dl class="simple">
<dt>Navigate to <cite>qairt/&lt;QNN_SDK_VERSION&gt;</cite> inside the unzipped QNN SDK.</dt><dd><ol class="arabic simple">
<li><p>Replace <cite>&lt;QNN_SDK_VERSION&gt;</cite> with the name of the file directly under <cite>qairt</cite> - it should look something like <cite>2.22.6.240515</cite>.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Run <cite>cd bin</cite>.</p></li>
<li><p>Run <cite>source ./envsetup.sh</cite>.</p>
<blockquote>
<div><p>This will automatically set the environment variables <cite>QNN_SDK_ROOT</cite> and <cite>SNPE_ROOT</cite>.</p>
<ol class="arabic simple">
<li><p><cite>QNN_SDK_ROOT</cite> - This points to the <cite>qairt/QNN_SDK_ROOT</cite> folder where the QNN SDK code lives.</p></li>
<li><p><cite>PYTHONPATH</cite> - The location of your local Python installation.</p></li>
<li><p><cite>PATH</cite> - The path to executables that are provided by QNN.</p></li>
<li><p><cite>LD_LIBRARY_PATH</cite> - The Linux Distribution Library Path points towards the proper build tools for your host machine‚Äôs operating system and hardware.</p></li>
</ol>
<p>&lt;aside&gt;
‚ö†Ô∏è The <cite>envsetup.sh</cite> script only updates environment variables for the current terminal session. If you need to set <cite>QNN_SDK_ROOT</cite> again, just re-run this script.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Run <cite>sudo ${QNN_SDK_ROOT}/bin/check-linux-dependency.sh</cite>.</p>
<blockquote>
<div><p>This will install the Linux build tools. When you have installed all the necessary dependencies, the script will say ‚ÄúDone!!‚Äù.</p>
<p>&lt;aside&gt;
üí° As the script is running, you will have to confirm additional downloads by pressing ‚ÄúEnter‚Äù. The script may take several minutes to complete.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Run <cite>${QNN_SDK_ROOT}/bin/envcheck -c</cite>.</p>
<blockquote>
<div><p>This will verify that you have installed the required toolchain successfully.</p>
</div></blockquote>
</li>
</ol>
<p>## 2. Install QNN SDK dependencies</p>
<ol class="arabic">
<li><p>Install python 3.10 by running the following commands:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">`bash</span>
<span class="pre">sudo</span> <span class="pre">apt-get</span> <span class="pre">update</span> <span class="pre">&amp;&amp;</span> <span class="pre">sudo</span> <span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">python3.10</span> <span class="pre">python3-distutils</span> <span class="pre">libpython3.10</span>
<span class="pre">`</span></code></p>
</div></blockquote>
</li>
<li><p>Verify the installation worked by running:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">python3</span> <span class="pre">--version</span>
<span class="pre">`</span></code></p>
<p>&lt;aside&gt;
‚ö†Ô∏è Ensure you have Python 3.10. The QNN SDK was verified with Python version 3.10.4.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Run <cite>cd ${QNN_SDK_ROOT}</cite>.</p></li>
<li><p>Install <cite>python3.10-venv</cite> if you don‚Äôt have it installed already by running:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">`bash</span>
<span class="pre">sudo</span> <span class="pre">apt</span> <span class="pre">install</span> <span class="pre">python3.10-venv</span>
<span class="pre">`</span></code></p>
</div></blockquote>
</li>
<li><p>Run the following command to create and activate a new virtual environment (you may rename <cite>MY_ENV_NAME</cite> to any name you prefer):</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">venv</span> <span class="pre">MY_ENV_NAME</span> <span class="pre">--without-pip</span>
<span class="pre">source</span> <span class="pre">MY_ENV_NAME/bin/activate</span>
<span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">ensurepip</span> <span class="pre">--upgrade</span>
<span class="pre">`</span></code></p>
<p>&lt;aside&gt;
‚ö†Ô∏è We have to use the flag <cite>‚Äìwithout-pip</cite> on Debian/Ubuntu systems to avoid a crash since venv will call <cite>ensurepip</cite> at the system level (which is disabled on Debian/Ubuntu). Once we activate our venv, we can then safely call <cite>ensurepip</cite> to create a local pip for installing packages.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Run <cite>which pip3</cite> to verify that the virtual environment has a local version of <cite>pip3</cite>.</p>
<blockquote>
<div><p>You should see a path that is inside your virtual environment (Ex. <cite>/MY_ENV_NAME/bin/pip3</cite>)</p>
</div></blockquote>
</li>
<li><p>Update all dependencies by running the following command:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">python</span> <span class="pre">&quot;${QNN_SDK_ROOT}/bin/check-python-dependency&quot;</span>
<span class="pre">`</span></code></p>
</div></blockquote>
</li>
</ol>
<p>## 3. Install Model Frameworks</p>
<p>These are the packages that interpret your AI model files. For example, the <cite>PyTorch</cite> package interprets <cite>.pt</cite> files.</p>
<p>&lt;aside&gt;
‚ö†Ô∏è Install any/all of the frameworks you want to use AI models from. You can install a package by running <cite>pip3 install package==version</cite>.
e.g., <cite>pip3 install torch==1.13.1</cite></p>
<p>&lt;/aside&gt;</p>
<div class="line-block">
<div class="line">Package | Version | Description |</div>
<div class="line">‚Äî | ‚Äî | ‚Äî |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/torch/">https://pypi.org/project/torch/</a> | 1.13.1 | PyTorch is used for building and training deep learning models with a focus on flexibility and speed. Used with .pt files. Install by downloading the proper binary <a class="reference external" href="https://pytorch.org/get-started/previous-versions/#v1130">https://pytorch.org/get-started/previous-versions/#v1130</a> if pip install does not work. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/torchvision/">https://pypi.org/project/torchvision/</a>  | 0.14.1 | Torchvision is used for computer vision tasks with PyTorch, providing datasets, model architectures, and image transforms. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/tensorflow/">https://pypi.org/project/tensorflow/</a> | 2.10.1 | Tensorflow is used for building and training machine learning models, particularly deep learning models. Used with .pb files. NOTE: The envcheck script will incorrectly say this file is not installed on Ubuntu.  |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/tflite/">https://pypi.org/project/tflite/</a> | 2.3.0 | TFLite is used for running TensorFlow models on mobile and edge devices with optimized performance. Used with .tflite files. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/onnx/">https://pypi.org/project/onnx/</a> | 1.12.0 | ONNX stands for Open Neural Network Exchange. It is used for defining and exchanging deep learning models between different frameworks. Used with .onnx files. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/onnxruntime/">https://pypi.org/project/onnxruntime/</a> | 1.17.1 | ONNX stands for Open Neural Network Exchange. It is used for running ONNX models with high performance across various hardware platforms. Used with .onnx files. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/onnxsim/">https://pypi.org/project/onnxsim/</a> | 0.4.36 | Onnxsim is used for simplifying ONNX models to reduce complexity and improve inference efficiency. Used with .onnx files. |</div>
</div>
<p>&lt;aside&gt;
‚≠ê You can verify your installation by calling <cite>${QNN_SDK_ROOT}/bin/envcheck -a</cite> which will check to see whether these dependencies are installed. These are optional, so just verify that the dependencies you intended to install are actually installed.</p>
<p>&lt;/aside&gt;</p>
<p>## 4. Install Target Device OS-Specific Toolchain Code</p>
<p>Depending on the target device‚Äôs operating system, there may be additional installation requirements.</p>
<p>### Working with an Android Target Device</p>
<p>For working with Android devices, you will need to install a corresponding Android NDK (Native Developer Kit). You can install the recommended version (Android NDK version <cite>r26c</cite>) by following these steps:</p>
<ol class="arabic">
<li><p>Download the Android NDK: <a class="reference external" href="https://dl.google.com/android/repository/android-ndk-r26c-linux.zip">https://dl.google.com/android/repository/android-ndk-r26c-linux.zip</a></p></li>
<li><p>Unzip the file.</p>
<blockquote>
<div><p>&lt;aside&gt;
‚ö†Ô∏è If your environment is in WSL, the Android NDK must be unzipped under $HOME with the WSL <cite>unzip</cite> command.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Open a terminal.</p></li>
<li><p>Add the location of the unzipped file to your PATH by running:</p>
<blockquote>
<div><p>&lt;aside&gt;
‚ö†Ô∏è Ensure you update the <cite>&lt;path-to-your-android-ndk-root-folder&gt;</cite> below to be the path to the unzipped <cite>android-ndk-r26c</cite> folder before running the below commands! (Ex. <cite>/home/usr/Documents/android-ndk-r26c</cite>)</p>
<p>&lt;/aside&gt;</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">echo</span> <span class="pre">'export</span> <span class="pre">ANDROID_NDK_ROOT=&lt;path-to-your-android-ndk-root-folder&gt;'</span> <span class="pre">&gt;&gt;</span> <span class="pre">~/.bashrc</span>
<span class="pre">echo</span> <span class="pre">'export</span> <span class="pre">PATH=${ANDROID_NDK_ROOT}:${PATH}'</span> <span class="pre">&gt;&gt;</span> <span class="pre">~/.bashrc</span>
<span class="pre">source</span> <span class="pre">~/.bashrc</span>
<span class="pre">`</span></code></p>
</div></blockquote>
</li>
<li><p>Verify your environment variables by running:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">${QNN_SDK_ROOT}/bin/envcheck</span> <span class="pre">-n</span>
<span class="pre">`</span></code></p>
</div></blockquote>
</li>
</ol>
<p>### Working with a Linux Target Device</p>
<p>For Linux target devices, you will likely need to use clang++14 to build models for them using the QNN SDK. Later versions may work but have not been verified.</p>
<p>You can verify if you have <cite>clang++14</cite> by running:</p>
<p><code class="docutils literal notranslate"><span class="pre">`jsx</span>
<span class="pre">${QNN_SDK_ROOT}/bin/envcheck</span> <span class="pre">-c</span>
<span class="pre">`</span></code></p>
<p>If not, please install clang++14 from LLVM: <a class="reference external" href="https://clang.llvm.org/cxx_status.html">https://clang.llvm.org/cxx_status.html</a></p>
<p>## 5. Install Dependencies for Target Hardware Processors</p>
<p>Some of the target processors (CPU, GPU, HTP, cDSP, or HTA) require additional dependencies to build models.</p>
<p><strong>CPU (Central Processing Unit)</strong></p>
<p>The x86_64 targets are built using clang-14. If working with this kind of target, please install clang++14 from LLVM: <a class="reference external" href="https://clang.llvm.org/cxx_status.html">https://clang.llvm.org/cxx_status.html</a></p>
<p>The ARM CPU targets are built using the Android NDK (see ‚ÄúWorking With an Android Target Device‚Äù).</p>
<p><strong>GPU (Graphical Processing Unit)</strong></p>
<p>The GPU backend kernels are written based on OpenCL. The GPU operations must be implemented based on OpenCL headers with a minimum version of OpenCL 1.2.</p>
<p><strong>HTP and DSP</strong></p>
<p>Compiling for both HTP and DSP hardware requires the use of the Qualcomm Hexagon SDK and Hexagon SDK Tools which you can install by following these steps.</p>
<ol class="arabic">
<li><dl>
<dt>If you do not already have Qualcomm Package Manager 3 (QPM3) installed, install it by following the steps below:</dt><dd><ol class="arabic">
<li><p>Sign into <a class="reference external" href="https://qpm.qualcomm.com/#/main/tools/details/QPM3">https://qpm.qualcomm.com/#/main/tools/details/QPM3</a>.</p>
<blockquote>
<div><p>&lt;aside&gt;
‚ö†Ô∏è You may have to reclick the link after logging in to have it load properly.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Download the Linux version of Qualcomm Package Manager 3 (QPM3).</p></li>
<li><p>Open the installer and click ‚ÄúInstall‚Äù.</p></li>
<li><dl class="simple">
<dt>Once installed, open ‚ÄúQualcomm Package Manager‚Äù.</dt><dd><ol class="arabic simple">
<li><p>For Ubuntu, click ‚ÄúActivities‚Äù and search for ‚ÄúQualcomm‚Äù then click the blue application.</p></li>
</ol>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
</li>
<li><p>Start QPM3 by running the QPM3 exectuable.</p></li>
<li><p>Create a Qualcomm account or log in to your existing one when prompted by QPM3.</p></li>
<li><p>Once logged in to QPM3, click on ‚ÄúTools.‚Äù</p></li>
<li><p>Search for ‚ÄúHexagon SDK‚Äù and download the proper version for your target device.</p>
<blockquote>
<div><p>&lt;aside&gt;
‚≠ê You can find the ‚ÄúHexagon Architecture‚Äù of your chip by looking up your chip type in the ‚ÄúSupported Snapdragon Devices‚Äù table [here](<a class="reference external" href="https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/overview.html#supported-snapdragon-devices">https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/overview.html#supported-snapdragon-devices</a>).</p>
<p>&lt;/aside&gt;</p>
<div class="line-block">
<div class="line">Backend | Hexagon Architecture | Hexagon SDK Version | Additional Notes |</div>
<div class="line">‚Äî | ‚Äî | ‚Äî | ‚Äî |</div>
<div class="line">HTP | V75 | 5.4.0 |  |</div>
<div class="line">HTP | V73 | 5.4.0 |  |</div>
<div class="line">HTP | V69 | 4.3.0 |  |</div>
<div class="line">HTP | V68 | 4.2.0 | Not pre-packaged with Hexagon SDK Tools. |</div>
<div class="line">DSP | V66 | 4.1.0 | Not pre-packaged with Hexagon SDK Tools. |</div>
<div class="line">DSP | V65 | 3.5.2 | Must be downloaded manually¬†<a class="reference external" href="https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools">https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools</a>¬†instead of from QPM3. Not pre-packaged with Hexagon SDK Tools. |</div>
</div>
<p>&lt;aside&gt;
‚≠ê Hexagon SDK Tools version 8.4.09/8.4.06/8.3.07 is¬†<strong>not</strong>¬†currently pre-packaged into Hexagon SDK version 4.2.0/4.1.0/3.5.2 respectively. It needs to be downloaded separately and placed at the location <cite>$HEXAGON_SDK_ROOT/tools/HEXAGON_Tools/</cite>.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Search for ‚ÄúHexagon Tools‚Äù and download the proper version for your target device.</p>
<blockquote>
<div><p>Based on your device‚Äôs architecture version, use the following table to determine which versions to download.</p>
<p>&lt;aside&gt;
‚≠ê You can find the ‚ÄúHexagon Architecture‚Äù of your chip by looking it up in the ‚ÄúSupported Snapdragon Devices‚Äù table [here](<a class="reference external" href="https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/overview.html#supported-snapdragon-devices">https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/overview.html#supported-snapdragon-devices</a>).</p>
<p>&lt;/aside&gt;</p>
<div class="line-block">
<div class="line">Backend | Hexagon Architecture | Hexagon Tools Version | Additional Notes |</div>
<div class="line">‚Äî | ‚Äî | ‚Äî | ‚Äî |</div>
<div class="line">HTP | V75 | 8.7.03 |  |</div>
<div class="line">HTP | V73 | 8.6.02 |  |</div>
<div class="line">HTP | V69 | 8.5.03 |  |</div>
<div class="line">HTP | V68 | 8.4.09 | Not pre-packaged. |</div>
<div class="line">DSP | V66 | 8.4.06 | Not pre-packaged. |</div>
<div class="line">DSP | V65 | 8.3.07 | Not pre-packaged. |</div>
</div>
<p>&lt;aside&gt;
‚≠ê Hexagon SDK Tools version 8.4.09/8.4.06/8.3.07 is¬†<strong>not</strong>¬†currently pre-packaged into Hexagon SDK version 4.2.0/4.1.0/3.5.2 respectively. It needs to be downloaded separately and placed at the location <cite>$HEXAGON_SDK_ROOT/tools/HEXAGON_Tools/</cite>.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Install clang++ so you can compile code for HTP/DSP hardware.</p></li>
<li><p>Follow the instructions at <cite>$HEXAGON_SDK_ROOT/docs/readme.html</cite> (where <cite>$HEXAGON_SDK_ROOT</cite> is the location of the Hexagon SDK installation).</p></li>
</ol>
<p>### LPAI (Low Power AI)</p>
<p>The LPAI backend is designed for offline model preparation only. In order to use QNN with LPAI, you must download the LPAI code using Qualcomm Package Manager.</p>
<ol class="arabic">
<li><dl>
<dt>If you do not already have Qualcomm Package Manager 3 (QPM3) installed, install it by following the steps below:</dt><dd><ol class="arabic">
<li><p>Sign into <a class="reference external" href="https://qpm.qualcomm.com/#/main/tools/details/QPM3">https://qpm.qualcomm.com/#/main/tools/details/QPM3</a>.</p>
<blockquote>
<div><p>&lt;aside&gt;
‚ö†Ô∏è You may have to reclick the link after logging in to have it load properly.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Download the Linux version of Qualcomm Package Manager 3 (QPM3).</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Start QPM3 by running the QPM3 executable.</p></li>
<li><p>Create a Qualcomm account or log in to your existing one when prompted.</p></li>
<li><p>Once logged in to the Qualcomm Package Manager, open the ‚ÄúTools‚Äù category.</p></li>
<li><dl>
<dt>Search for ‚ÄúLPAI‚Äù and click the ‚ÄúExtract‚Äù button.</dt><dd><ol class="arabic">
<li><p>This will attempt to install the LPAI code, <strong>but will likely fail</strong> because it is missing the Hexagon SDK dependency.</p></li>
<li><dl class="simple">
<dt>Use the error message to determine which version of the Hexagon SDK you need to install first.</dt><dd><ol class="arabic simple">
<li><p>e.g., For v2.4.0 of the LPAI code, it requires version 5.x of the Hexagon SDK.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Install the necessary version of the Hexagon SDK.</p>
<blockquote>
<div><p>&lt;aside&gt;
‚ö†Ô∏è If an installation fails because QPM3 cannot access a folder, move the installation path to one which does not require sudo access.</p>
<p>&lt;/aside&gt;</p>
</div></blockquote>
</li>
<li><p>Then re-install the LPAI code.</p></li>
</ol>
</dd>
</dl>
</li>
</ol>
<p>## 5. (Optional) Additional Packages for Evaluating Model Accuracy</p>
<p>If you want to evaluate model accuracy in real time, you may also need to install some of the following dependencies.</p>
<p>You can install each relevant package by running:</p>
<p><cite>pip3 install dependency==version</cite></p>
<p>e.g., <cite>pip3 install pycocotools==2.0.6</cite></p>
<div class="line-block">
<div class="line">Package | Version | Description |</div>
<div class="line">‚Äî | ‚Äî | ‚Äî |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/pycocotools/">https://pypi.org/project/pycocotools/</a> | 2.0.6 | Use for working with COCO datasets for object detection, segmentation, and keypoint tasks. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/transformers/">https://pypi.org/project/transformers/</a> | 4.31.0 | Use for leveraging pre-trained models for various NLP tasks like text classification, translation, and more. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/tokenizers/">https://pypi.org/project/tokenizers/</a> | 0.19.1 | Use for efficient tokenization of text data, particularly when dealing with large datasets. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/sacrebleu/">https://pypi.org/project/sacrebleu/</a> | 2.3.1 | Use for evaluating the quality of machine translation models. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/scikit-learn/">https://pypi.org/project/scikit-learn/</a> | 1.3.0 | Use for implementing machine learning algorithms and models for various predictive tasks. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/OpenNMT-py/">https://pypi.org/project/OpenNMT-py/</a> | 2.3.0 | Use for building and training neural machine translation models. |</div>
<div class="line"><a class="reference external" href="https://pypi.org/project/sentencepiece/">https://pypi.org/project/sentencepiece/</a> | 0.1.98 | Use for unsupervised text tokenization and preprocessing for language models. |</div>
</div>
<p>## Next Steps</p>
<p>Now that you‚Äôve finished setting up QNN SDK and its dependencies, you can use the QNN SDK. Follow the [CNN to QNN tutorial](<a class="reference external" href="https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/tutorial2.html">https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/tutorial2.html</a>) to learn how to transform your AI models, build them for your target device, and use them to generate inferences on the information processing cores you choose. Use the QNN SDK to allow your AI models to execute on your specific target device‚Äôs cores.</p>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2024, Qualcomm Technologies, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>